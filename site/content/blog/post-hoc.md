+++
author = "S"
categories = ["学術"]
date = ""
draft = true
tags = []
thumbnail = ""
title = "分散分析の視覚的理解ー事後検定禁止令"

+++
統計なんて大っ嫌いだ　Jan.23.2021

***

警告：これは由緒正しき正規分布帝国の布教活動です。ノンパラメトリック自治領の方は(以下略)

※わかりやすさ重視なので厳密性はゆるゆるです。決して教科書の代替ではないのでご了承ください。というか、教科書を読む前に知っておきたかったことをまとめた感じです。

※一応t検定の基礎あたりまでを勉強している前提で書いてます。えっと、、、言い換えれば、これ以降の内容が電波系の戯言だと感じなかったら大丈夫です。

世界の始まり、由緒正しき正規分布皇帝は”平均あれ”と言われた。

すると人々の目は開かれ、あらゆる事物の平均が目に映った。人々は物事の本質が見えたと喜んだ。

~~しかし、なぜ平均値がモノゴトの本質を表すのか?それはここが中心極限定理に守られた由緒正しき正規分布帝国だからである。~~

時は流れ、我々は今でもこの言葉に~~憑りつかれている~~忠実である。
これを我々はこう表しました。

<span style="color: red; ">Y</span> = μ + ε
(日本語訳:)<span style="color: red; ">こいつ</span>は平均くらいなはずですが、平均からズレてる分については誤差としましょう。

![](/img/y-u-e.jpg)

**まず、世界全体の平均があり、世の全てのモノゴトは平均からの距離、すなわち誤差の大きさで説明される。**

智に働けば角が立つ。情に棹させば流される。

そりゃあうまくいかねえわけです。

そこで宗教革命！

効果なるものを唱えたヤツがおるわけです。

Y = μ + ε
↓
Y = μ + A + ε
(日本語訳:)こいつは平均からAの影響分ズレています。それで説明できない部分は誤差としましょう。

(さらに日本語訳:)平均値を見比べれば違いがあるかわかる。

人々はモノゴトをグループに分けて、異なる群の平均どうしを比べはじめたのです。これにより世界は分断されてしまいました。

でもどうやって平均の違いを考えましょうか?

データのバラツキがどこで生じたのかを考えるのです。系統的なバラツキがあれば、何かしらのシステマティックな影響、すなわち効果があるということです。

バラツキを指標化した値が皆さんご存じ分散(√を付ければ標準偏差)です。分散を基準に評価する分析法なのでANOVA(分散分析、analysis of variance)と言います。

なんかこの調子で続けても電波濃度が上がるだけな気がするのでそろそろ数字を登場させましょう。例えば、Itamae・ぽ・Johsonの3人にそれぞれチュパカブラの卵を3つずつ渡して1年間育ててもらって1年後に体長を測って成長を見たとしましょう。

![](/img/1waytable1.jpg)

誰が育てたかによってチュパカブラの成長には差があるのでしょうか? one-way between ANOVA(対応の無い一元配置分散分析)で分析してみましょう。

分散で評価するということなので、まずはデータの各値を下のように変形します。

Y = μ + A + ε
↓
Y - μ = A + ε

分散の定義はY-μの二乗の合計をN数で割ることですが、異なるサンプルサイズの比較はしないのでNで割らなくても合計のままで比較できます。この二乗の和をSS(平方和、sum of squares/squared sum)と言います。

※合計するときに相殺されないように二乗にするのは分散の計算と同じ考え方です。

Σ{(Y-μ)^2}= Σ(A)^2 + Σ(ε)^2 →これを”SS”と呼びます→SS(total) = SS(A) + SS(ε)

※SS(total)/N = VAR(Y) = SD(Y)^2

![](/img/1waytable2.jpg)

ここで、こう考えます。

Y = μ + A + ε  →→  SS(total) = SS(A) + SS(ε)

①もし条件による差が全く影響していなければ、そもそも条件平均は総平均と全く同じになるはずです。(Y=μ+ε → SS(A)=0, SS(total)=SS(ε))。

②もしデータ内のバラツキが全て条件による影響Ａだけで説明されるとしたら、各条件内では全く同じ値を取っているはずです(Y=μ+A → SS(total)=SS(A), SS(ε)=0)。

SS(total)を構成するSS(A)とSS(ε)の比を比較することで主効果Aの強さを評価しようという考え方です。

でも大抵の場合、

でも、直接比較してはいけません。

ここで思い出してください。ここは由緒正しき正規分布帝国です。残差は正規分布に従うのです(拍手)。

そうなんです。だからt検定の時みたいにt分布をつかうことはできません。自由度を考慮する必要があります。自由度の直感的に説明ってなかなかないのでじっくり説明したいところですが、、、長くなりすぎるので今回は残念ながら端折ります。

ここでF分布ってのを登場させる必要があります。統計を学ぶ時、教科書上ではだいたい正規分布→χ²分布→F分布→T分布の順番で載っています。でも分析方法を学ぶ時の順番はだいたいT検定→ANOVAとなります。分布の導出と利用が逆なんです。

だからなにがなんだかようわからん、ということが起こります。ANOVAを学ぶうえでの最初の感動はt分布を正規分布→χ²分布→F分布→T分布の流れで理解することなのです。

ここで、独立変数をもう一つ増やしてtwo-way between ANOVA(対応の無い2元配置分散分析)を見てみましょう。

変数Aと変数Bそれぞれの効果、それに加えてAとBの交互作用というものを考える必要があります。交互作用というのは相乗効果のことです。プロフェッサーの説明↓

風邪をひいたとき、風邪薬を飲みますね。市販の風邪薬にはエフェドリンとリン酸ジヒドロコデインって麻薬成分が含まれてるんだけど、それぞれ単独で飲んでも大したことはないのが、あわせて呑むとハイになれるんですね～。

OTC薬の量で実際に効果出るのかは筆者も気になるところではあります(笑)。

ちなみに交互作用は強く出るだけ以外にも拮抗する形のこともあります。例えばテトロドトキシンとアコニチンを同時に摂取すると効果が拮抗するよ、みたいな話です。

話を戻して、2変数の場合も同じです。バラツキの大きさで効果を評価します。

within ANOVA(対応のある分散分析)については、実は普通のbetween ANOVAのモデルに効果をもうひとつ追加しただけです。被験者を独立変数として追加して、一人ひとりの被験者を条件と捉えているだけなのです。

Y = μ + A + S + ε

one-way within ANOVAでは上のように被験者効果Sというものが加わります。被験者効果と言っていますが、この先の取り扱いはtwo-way between ANOVAと全く同じです。

(期待してる突っ込み)主効果Aと被験者効果Sの交互作用ASは無くても良いの?

交互作用ASは存在します。実は交互作用は残差εに一致するんです。これは各項の自由度を考えれば納得できます。自由度を説明していると終わらなくなるのですいませんが、この先は教科書に投げます。

***

さて、日本の教科書に書いてあるのはここまで！
ここから先の内容は日本国内ではあまり浸透していません。
ですが！
この手法は実験統計の世界ではメジャーな存在です。
そして大学の実験計画法の授業では必ず学びます(少なくとも欧米では)。

それがコントラストコーディング。

まず、ANOVAはGLM(一般線型モデル)の特殊形です。post-hoc法が論理的に誤り、というのはANOVAの回帰モデルを全く無視した解析を無理くり追加で組み合わせているからです。

そもそも論、ANOVAというのはSSを我々に都合が良いように切り分けているだけです。ならば、主効果のSSをさらに分解すれば回帰式を崩さずに条件間比較ができるのではないか?という考え方が第一選択であるべきです。

one-way between ANOVAを例に見てみましょう。

今まではこう書いてました。

Y = μ + A + ε

ここで、中身は全く変えないまま、主効果をこう書き直してみます。

Y = μ + βX + ε

なんか、GLMの基本形っぽくなった!って思った方は鋭い!

そうなんです、ここではβXはバラメータマトリックス×デザインマトリックスです(ただしそれは正確にはμ = β₀X₀の時)。

A = βX = β₁X₁ + β₂X₂ + ・・・ + β(df)X(df)

主効果を自由度の数の項に分解すれば条件間の比較ができるってことです!

ただし、うまく条件間比較をするためにはデザインマトリックスをうまい具合に設定する必要があります。この行列Xをどう設定するか(コーディング)が非常に重要なポイントです。

コーディングには、いくつか種類があります(例えば、名義尺度変数で使うダミーコーディング)。ANOVAで使うのはコントラストコーディングです。コントラストコーディングには2つの特徴があるます。①全ての条件が比較が比較に含まれていること、そして②各比較が独立であることです。

説明だけじゃピンとこないと思うので、まずは、2条件の比較(independent t-test)について考えてみましょう。

t検定とは、A1、A2の2条件について以下のようなコントラストでANOVAを行うということです。Xは(1,-1)で足し合わせると0なので独立な比較です。

![](/img/t_contrast.jpg)

コントラストはX = (1, -1)となっていますが、逆にしても符号が逆転するだけで解析は本質的に変わりません。

これを以下の式にあてはめます。

Y = μ+βX＋ε

ここで、Xは列ベクトルですので実際には条件別にこういうことになります。

A1 : Y = μ +β ＋ε
A2 : Y = μ -β ＋ε

これを図で表すとこうです↓。※ただし、A1>A2→β>0、A1<A2→β<0。残差εはA1またはA2から各点へのバラツキ。

![](/img/ttest.jpg)

各条件は平均からβズレているということです(A1とA2でNが違うと成り立たない)。この時の帰無仮説はβ = 0、すなわちA1 = A2 = μです。

βの導出ができなくてもANOVAでは困りません(YにXの一般化逆行列をかけます)。

ここまでは従来の分析と同じです。ここでさらに、3条件(one-way between ANOVA)についてみてみましょう。

以下のようなコントラストを用いたANOVAを考えてみましょう。

![](/img/anova_contrast.jpg)

X1ではA1とA2&A3を比較して、X2ではA2とA3を比較します。X1、X2でそれぞれ何を比較するかは実験や解析の論理的な文脈で決めます。X1もX2もそれぞれの総和が0なので独立な比較です。

これも同様にGLMの式に入れます。

Y = μ＋β₁X₁＋β₂X₂＋ε

Xを各条件ごとにバラして並べてみると、、

A1：Y = μ＋2β₁＋ε
A2：Y = μ – β₁＋β₂＋ε
A3：Y = μ－β₁－β₂＋ε

各条件が平均からβ2つ分ズレているという形で表記されていることがわかります。df=2に分解できたということです。

これも図に表してみると以下のようになります。※必ずしも図のようにA1>A2>A3(すなわちβ₁,β₂>0)だとは限らない

![](/img/anova.jpg)

これはすなわちX₁について見ると、

帰無仮説β₁＝0を棄却→A1とA2&A3には差がある

と言うことが言えますし、X₂も同様に、

帰無仮説β₂＝0を棄却→A2とA3には差がある

と言える、というロジックです。

β₁X₁のSSとβ₂X₂のSSは大きさこそ違いますが、βの”重み”は同じですし、足し合わせるともとの主効果AのSSに一致します。この点、やはりpost-hocよりロジックが美しいですよね。

結論：理由もなく安易にpost-hocを持ち出すと人権を失います。

以上、おしまい。

まだまだ2-wayだのwithinだのありますが、基本は全部同じ考え方です。そしてその先には混合モデルだの階層モデルだのANCOVAだのANOVA属の底はまだまだ深いです泣。

相当端折りましたので、実際に使う方は是非教科書を読んでください。素晴らしいことにめっちゃわかりやすい名著がネット上で公開されています↓。

[https://www.researchgate.net/profile/Barbara_Tabachnick/publication/259465542_Experimental_Designs_Using_ANOVA/links/5e6bb05f92851c6ba70085db/Experimental-Designs-Using-ANOVA.pdf](https://www.researchgate.net/profile/Barbara_Tabachnick/publication/259465542_Experimental_Designs_Using_ANOVA/links/5e6bb05f92851c6ba70085db/Experimental-Designs-Using-ANOVA.pdf "https://www.researchgate.net/profile/Barbara_Tabachnick/publication/259465542_Experimental_Designs_Using_ANOVA/links/5e6bb05f92851c6ba70085db/Experimental-Designs-Using-ANOVA.pdf")